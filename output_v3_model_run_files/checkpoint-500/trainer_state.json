{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.07546030787805615,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.001509206157561123,
      "grad_norm": 4.526779651641846,
      "learning_rate": 0.0004983333333333334,
      "loss": 1.7812,
      "step": 10
    },
    {
      "epoch": 0.003018412315122246,
      "grad_norm": 3.6299264430999756,
      "learning_rate": 0.0004966666666666666,
      "loss": 1.2615,
      "step": 20
    },
    {
      "epoch": 0.004527618472683369,
      "grad_norm": 2.523728370666504,
      "learning_rate": 0.000495,
      "loss": 0.8381,
      "step": 30
    },
    {
      "epoch": 0.006036824630244492,
      "grad_norm": 4.617517948150635,
      "learning_rate": 0.0004933333333333334,
      "loss": 1.1124,
      "step": 40
    },
    {
      "epoch": 0.007546030787805615,
      "grad_norm": 4.280418872833252,
      "learning_rate": 0.0004916666666666666,
      "loss": 1.0023,
      "step": 50
    },
    {
      "epoch": 0.009055236945366738,
      "grad_norm": 4.2745842933654785,
      "learning_rate": 0.00049,
      "loss": 1.1932,
      "step": 60
    },
    {
      "epoch": 0.01056444310292786,
      "grad_norm": 3.2863259315490723,
      "learning_rate": 0.0004883333333333333,
      "loss": 1.0693,
      "step": 70
    },
    {
      "epoch": 0.012073649260488983,
      "grad_norm": 4.149944305419922,
      "learning_rate": 0.0004866666666666667,
      "loss": 1.0359,
      "step": 80
    },
    {
      "epoch": 0.013582855418050106,
      "grad_norm": 5.123433589935303,
      "learning_rate": 0.00048499999999999997,
      "loss": 1.15,
      "step": 90
    },
    {
      "epoch": 0.01509206157561123,
      "grad_norm": 2.4548261165618896,
      "learning_rate": 0.00048333333333333334,
      "loss": 0.9322,
      "step": 100
    },
    {
      "epoch": 0.016601267733172352,
      "grad_norm": 2.6163525581359863,
      "learning_rate": 0.0004816666666666667,
      "loss": 1.052,
      "step": 110
    },
    {
      "epoch": 0.018110473890733475,
      "grad_norm": 3.650675058364868,
      "learning_rate": 0.00048,
      "loss": 1.4148,
      "step": 120
    },
    {
      "epoch": 0.019619680048294598,
      "grad_norm": 4.163342475891113,
      "learning_rate": 0.0004783333333333333,
      "loss": 1.107,
      "step": 130
    },
    {
      "epoch": 0.02112888620585572,
      "grad_norm": 2.6465706825256348,
      "learning_rate": 0.0004766666666666667,
      "loss": 0.9945,
      "step": 140
    },
    {
      "epoch": 0.022638092363416844,
      "grad_norm": 4.102530002593994,
      "learning_rate": 0.000475,
      "loss": 0.784,
      "step": 150
    },
    {
      "epoch": 0.024147298520977967,
      "grad_norm": 5.171638011932373,
      "learning_rate": 0.00047333333333333336,
      "loss": 1.2555,
      "step": 160
    },
    {
      "epoch": 0.02565650467853909,
      "grad_norm": 4.003929615020752,
      "learning_rate": 0.0004716666666666667,
      "loss": 0.9605,
      "step": 170
    },
    {
      "epoch": 0.027165710836100213,
      "grad_norm": 4.162509918212891,
      "learning_rate": 0.00047,
      "loss": 1.0895,
      "step": 180
    },
    {
      "epoch": 0.028674916993661335,
      "grad_norm": 5.338866233825684,
      "learning_rate": 0.00046833333333333335,
      "loss": 1.152,
      "step": 190
    },
    {
      "epoch": 0.03018412315122246,
      "grad_norm": 3.918215274810791,
      "learning_rate": 0.00046666666666666666,
      "loss": 1.0471,
      "step": 200
    },
    {
      "epoch": 0.03169332930878358,
      "grad_norm": 2.553309440612793,
      "learning_rate": 0.000465,
      "loss": 1.2008,
      "step": 210
    },
    {
      "epoch": 0.033202535466344704,
      "grad_norm": 5.488369464874268,
      "learning_rate": 0.00046333333333333334,
      "loss": 1.3684,
      "step": 220
    },
    {
      "epoch": 0.03471174162390583,
      "grad_norm": 3.3953678607940674,
      "learning_rate": 0.0004616666666666667,
      "loss": 1.0859,
      "step": 230
    },
    {
      "epoch": 0.03622094778146695,
      "grad_norm": 5.445623874664307,
      "learning_rate": 0.00046,
      "loss": 0.8508,
      "step": 240
    },
    {
      "epoch": 0.03773015393902807,
      "grad_norm": 2.3504083156585693,
      "learning_rate": 0.0004583333333333333,
      "loss": 1.0516,
      "step": 250
    },
    {
      "epoch": 0.039239360096589196,
      "grad_norm": 8.683120727539062,
      "learning_rate": 0.0004566666666666667,
      "loss": 1.1355,
      "step": 260
    },
    {
      "epoch": 0.04074856625415032,
      "grad_norm": 6.5666961669921875,
      "learning_rate": 0.000455,
      "loss": 0.9324,
      "step": 270
    },
    {
      "epoch": 0.04225777241171144,
      "grad_norm": 8.30313491821289,
      "learning_rate": 0.0004533333333333333,
      "loss": 1.1682,
      "step": 280
    },
    {
      "epoch": 0.043766978569272565,
      "grad_norm": 2.2594666481018066,
      "learning_rate": 0.0004516666666666667,
      "loss": 1.2047,
      "step": 290
    },
    {
      "epoch": 0.04527618472683369,
      "grad_norm": 4.166910171508789,
      "learning_rate": 0.00045000000000000004,
      "loss": 1.1027,
      "step": 300
    },
    {
      "epoch": 0.04678539088439481,
      "grad_norm": 3.9617397785186768,
      "learning_rate": 0.0004483333333333333,
      "loss": 1.0277,
      "step": 310
    },
    {
      "epoch": 0.04829459704195593,
      "grad_norm": 3.49330997467041,
      "learning_rate": 0.00044666666666666666,
      "loss": 1.0688,
      "step": 320
    },
    {
      "epoch": 0.049803803199517056,
      "grad_norm": 2.9284489154815674,
      "learning_rate": 0.00044500000000000003,
      "loss": 1.0012,
      "step": 330
    },
    {
      "epoch": 0.05131300935707818,
      "grad_norm": 2.4470107555389404,
      "learning_rate": 0.00044333333333333334,
      "loss": 1.0434,
      "step": 340
    },
    {
      "epoch": 0.0528222155146393,
      "grad_norm": 5.3538641929626465,
      "learning_rate": 0.00044166666666666665,
      "loss": 0.9137,
      "step": 350
    },
    {
      "epoch": 0.054331421672200425,
      "grad_norm": 4.424758434295654,
      "learning_rate": 0.00044,
      "loss": 1.0152,
      "step": 360
    },
    {
      "epoch": 0.05584062782976155,
      "grad_norm": 2.2221152782440186,
      "learning_rate": 0.0004383333333333334,
      "loss": 1.0074,
      "step": 370
    },
    {
      "epoch": 0.05734983398732267,
      "grad_norm": 8.342182159423828,
      "learning_rate": 0.00043666666666666664,
      "loss": 0.8652,
      "step": 380
    },
    {
      "epoch": 0.058859040144883794,
      "grad_norm": 4.247380256652832,
      "learning_rate": 0.000435,
      "loss": 0.9426,
      "step": 390
    },
    {
      "epoch": 0.06036824630244492,
      "grad_norm": 3.9363439083099365,
      "learning_rate": 0.00043333333333333337,
      "loss": 0.7859,
      "step": 400
    },
    {
      "epoch": 0.06187745246000604,
      "grad_norm": 3.390939950942993,
      "learning_rate": 0.0004316666666666667,
      "loss": 0.9373,
      "step": 410
    },
    {
      "epoch": 0.06338665861756716,
      "grad_norm": 1.9428819417953491,
      "learning_rate": 0.00043,
      "loss": 1.0242,
      "step": 420
    },
    {
      "epoch": 0.06489586477512828,
      "grad_norm": 2.896209955215454,
      "learning_rate": 0.00042833333333333335,
      "loss": 0.8498,
      "step": 430
    },
    {
      "epoch": 0.06640507093268941,
      "grad_norm": 5.313353538513184,
      "learning_rate": 0.0004266666666666667,
      "loss": 0.9557,
      "step": 440
    },
    {
      "epoch": 0.06791427709025052,
      "grad_norm": 4.082955360412598,
      "learning_rate": 0.000425,
      "loss": 0.9406,
      "step": 450
    },
    {
      "epoch": 0.06942348324781165,
      "grad_norm": 4.587948322296143,
      "learning_rate": 0.00042333333333333334,
      "loss": 0.8439,
      "step": 460
    },
    {
      "epoch": 0.07093268940537277,
      "grad_norm": 4.431200981140137,
      "learning_rate": 0.0004216666666666667,
      "loss": 1.1678,
      "step": 470
    },
    {
      "epoch": 0.0724418955629339,
      "grad_norm": 3.31732439994812,
      "learning_rate": 0.00042,
      "loss": 0.8273,
      "step": 480
    },
    {
      "epoch": 0.07395110172049502,
      "grad_norm": 1.845638632774353,
      "learning_rate": 0.00041833333333333333,
      "loss": 0.8957,
      "step": 490
    },
    {
      "epoch": 0.07546030787805615,
      "grad_norm": 1.3633835315704346,
      "learning_rate": 0.0004166666666666667,
      "loss": 0.9088,
      "step": 500
    },
    {
      "epoch": 0.07546030787805615,
      "eval_bleu-4": 0.046722778375846534,
      "eval_rouge-1": 27.196036875439834,
      "eval_rouge-2": 25.658205770584097,
      "eval_rouge-l": 8.26850239268121,
      "eval_runtime": 502.6535,
      "eval_samples_per_second": 2.827,
      "eval_steps_per_second": 0.708,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 3000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3885340999827456.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
